# mean-opinion-score

[![PyPI](https://img.shields.io/pypi/v/mean-opinion-score.svg)](https://pypi.python.org/pypi/mean-opinion-score)
[![PyPI](https://img.shields.io/pypi/pyversions/mean-opinion-score.svg)](https://pypi.python.org/pypi/mean-opinion-score)
[![MIT](https://img.shields.io/github/license/stefantaubert/mean-opinion-score.svg)](https://github.com/stefantaubert/mean-opinion-score/blob/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/wheel/mean-opinion-score.svg)](https://pypi.python.org/pypi/mean-opinion-score/#files)
![PyPI](https://img.shields.io/pypi/implementation/mean-opinion-score.svg)
[![PyPI](https://img.shields.io/github/commits-since/stefantaubert/mean-opinion-score/latest/master.svg)](https://github.com/stefantaubert/mean-opinion-score/compare/v0.0.1...master)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7669641.svg)](https://doi.org/10.5281/zenodo.7669641)

Python library to evaluate text-to-speech (TTS) mean opinion score (MOS) studies done on Amazon Mechanical Turk (MTurk).
The calculation of the confidence intervals is done in the same manner as described in (Ribeiro et al., 2011).

## Installation

```sh
pip install mean-opinion-score --user
```

## Usage

```py
import numpy as np

from mean_opinion_score import compute_mos, compute_ci95

_ = np.nan

ratings = np.array([
    # columns represent sentences
    # algorithm 1
    [
      [4, 5, _, 4],  # rater 1
      [4, 4, 4, 5],  # rater 2
      [_, 3, 5, 4],  # rater 3
      [_, _, _, _],  # rater 4
    ],
    # algorithm 2
    [
      [1, 2, _, _],  # rater 1
      [1, 1, 1, _],  # rater 2
      [_, 2, 5, 1],  # rater 3
      [_, 1, _, 1],  # rater 4
    ]
])

alg1_mos = compute_mos(ratings[0])
alg1_ci95 = compute_ci95(ratings[0])

print(f"MOS algorithm 1: {alg1_mos:.2f} ± {alg1_ci95:.4f}")
# MOS algorithm 1: 4.20 ± 0.6997

alg2_mos = compute_mos(ratings[1])
alg2_ci95 = compute_ci95(ratings[1])

print(f"MOS algorithm 2: {alg2_mos:.2f} ± {alg2_ci95:.4f}")
# MOS algorithm 2: 1.60 ± 1.7912
```

## Dependencies

- `numpy`
- `scipy`

## Contributing

If you notice an error, please don't hesitate to open an issue.

### Development setup

```sh
# update
sudo apt update
# install Python 3.8, 3.9, 3.10 & 3.11 for ensuring that tests can be run
sudo apt install python3-pip \
  python3.8 python3.8-dev python3.8-distutils python3.8-venv \
  python3.9 python3.9-dev python3.9-distutils python3.9-venv \
  python3.10 python3.10-dev python3.10-distutils python3.10-venv \
  python3.11 python3.11-dev python3.11-distutils python3.11-venv
# install pipenv for creation of virtual environments
python3.8 -m pip install pipenv --user

# check out repo
git clone https://github.com/stefantaubert/mean-opinion-score.git
cd mean-opinion-score
# create virtual environment
python3.8 -m pipenv install --dev
```

## Running the tests

```sh
# first install the tool like in "Development setup"
# then, navigate into the directory of the repo (if not already done)
cd mean-opinion-score
# activate environment
python3.8 -m pipenv shell
# run tests
tox
```

Final lines of test result output:

```log
  py36: commands succeeded
  py37: commands succeeded
  py38: commands succeeded
  py39: commands succeeded
  py310: commands succeeded
  py311: commands succeeded
  congratulations :)
```

## License

MIT License

## Acknowledgments

Calculation and template are based on:

- Ribeiro, F., Florêncio, D., Zhang, C., & Seltzer, M. (2011). CrowdMOS: An approach for crowdsourcing mean opinion score studies. 2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2416–2419. [https://doi.org/10.1109/ICASSP.2011.5946971](https://doi.org/10.1109/ICASSP.2011.5946971)

Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – Project-ID 416228727 – CRC 1410

## Citation

If you want to cite this repo, you can use this BibTeX-entry generated by GitHub (see *About => Cite this repository*).

```txt
Taubert, S. (2023). mean-opinion-score (Version 0.0.1) [Computer software]. https://doi.org/10.5281/zenodo.7669641
```

## Changelog

- v0.0.1 (2023-02-23)
  - Initial release
